{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T14:48:24.069636Z","iopub.execute_input":"2025-01-16T14:48:24.070038Z","iopub.status.idle":"2025-01-16T14:48:24.075611Z","shell.execute_reply.started":"2025-01-16T14:48:24.070007Z","shell.execute_reply":"2025-01-16T14:48:24.074582Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\ngroq_api_key = user_secrets.get_secret(\"groq_api_key\")\nhf_api_key = user_secrets.get_secret(\"hf_api_key\")\nNEO4J_PASSWORD = user_secrets.get_secret(\"NEO4J_PASSWORD\")\nNEO4J_URI = user_secrets.get_secret(\"NEO4J_URI\")\nNEO4J_USERNAME = user_secrets.get_secret(\"NEO4J_USERNAME\")\nimport huggingface_hub\nhuggingface_hub.login(token=hf_api_key)\nhuggingface_hub.auth_list()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T14:48:24.272373Z","iopub.execute_input":"2025-01-16T14:48:24.272766Z","iopub.status.idle":"2025-01-16T14:48:24.925105Z","shell.execute_reply.started":"2025-01-16T14:48:24.272732Z","shell.execute_reply":"2025-01-16T14:48:24.924251Z"}},"outputs":[{"name":"stdout","text":"  name   | token          \n---------|---------------\n* llms   | hf_****zPtR    \n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"### Important Links\n- https://neo4j.com/labs/genai-ecosystem/langchain/\n- https://python.langchain.com/docs/integrations/vectorstores/neo4jvector/","metadata":{}},{"cell_type":"markdown","source":"### Neo4j Login","metadata":{}},{"cell_type":"code","source":"from langchain_community.graphs import Neo4jGraph\nfrom langchain_groq import ChatGroq\nfrom typing import TypedDict, Annotated, List, Union\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.pydantic_v1 import BaseModel,Field\nfrom langchain_huggingface import HuggingFaceEmbeddings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T14:48:37.547606Z","iopub.execute_input":"2025-01-16T14:48:37.547990Z","iopub.status.idle":"2025-01-16T14:48:39.120206Z","shell.execute_reply.started":"2025-01-16T14:48:37.547959Z","shell.execute_reply":"2025-01-16T14:48:39.119083Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n\nFor example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\nwith: `from pydantic import BaseModel`\nor the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n\n  exec(code_obj, self.user_global_ns, self.user_ns)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"\ngraph = Neo4jGraph(\n    url=NEO4J_URI,\n    username=NEO4J_USERNAME,\n    password=NEO4J_PASSWORD)\n\nllm_model = ChatGroq(api_key = groq_api_key,\n                     model_name = 'llama-3.1-8b-instant')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T14:48:42.499066Z","iopub.execute_input":"2025-01-16T14:48:42.499594Z","iopub.status.idle":"2025-01-16T14:48:47.514068Z","shell.execute_reply.started":"2025-01-16T14:48:42.499557Z","shell.execute_reply":"2025-01-16T14:48:47.512984Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import torch\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nembeddings = HuggingFaceEmbeddings(model_name=\"jinaai/jina-embeddings-v3\",\n                                  encode_kwargs = {'normalize_embeddings': True},\n                                   model_kwargs = {'device': device,'trust_remote_code':'True',})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T15:22:19.174325Z","iopub.execute_input":"2025-01-16T15:22:19.174919Z","iopub.status.idle":"2025-01-16T15:22:35.017543Z","shell.execute_reply.started":"2025-01-16T15:22:19.174872Z","shell.execute_reply":"2025-01-16T15:22:35.016521Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/378 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef9855dd731047ee953b91956018c0c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/464 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a126f6571d544ecbf903625796d15c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/734k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35e58b0126b44dea8165150deabb9d3a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"custom_st.py:   0%|          | 0.00/8.78k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"068147033efd400cb058d89cffa50acc"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/jinaai/jina-embeddings-v3:\n- custom_st.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"708c505098ad4c6d9e575fe0c52ff975"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_xlm_roberta.py:   0%|          | 0.00/6.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1caa4ac035ae4600a8c2bb5437c261be"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n- configuration_xlm_roberta.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_lora.py:   0%|          | 0.00/15.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fda98da022c411dac1eacf9f2c36023"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modeling_xlm_roberta.py:   0%|          | 0.00/51.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d762cdffadf44e0a9f361e3e6fe6976e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"mlp.py:   0%|          | 0.00/7.62k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8cd9a52752248e0a84373429df4be6d"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n- mlp.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"embedding.py:   0%|          | 0.00/3.88k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abe10978e0b84723a5acd4be17688a9e"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n- embedding.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"block.py:   0%|          | 0.00/17.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6528950660e4c16b7e628a992b2dbb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"stochastic_depth.py:   0%|          | 0.00/3.76k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c1906ebafb5459bae3493fdac779257"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n- stochastic_depth.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"mha.py:   0%|          | 0.00/34.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc3ab58d4235496c9238c9b73744450e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"rotary.py:   0%|          | 0.00/24.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b86958eeec042eabe195ef98f7fb918"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n- rotary.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\nA new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n- mha.py\n- rotary.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\nA new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n- block.py\n- stochastic_depth.py\n- mha.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"xlm_padding.py:   0%|          | 0.00/10.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1041e153d8a4625951c5ea1ee5b2d4b"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n- xlm_padding.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\nA new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n- modeling_xlm_roberta.py\n- mlp.py\n- embedding.py\n- block.py\n- xlm_padding.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\nA new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n- modeling_lora.py\n- modeling_xlm_roberta.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.14G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f6584b266e740bb90eaf765bdcc8f37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f8c17cb678745b7ae8aa58d6fb1483b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"633944b22b784dbd966bdca979d0fea8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"609a7ec8aa744bc1b74b33e7a1002659"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/192 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec4a1f2228ac480ca782a4d124d36456"}},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"sample_embeddings = embeddings.embed_query(\"Maninder Singh\")\nprint(len(sample_embeddings))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T15:23:48.402557Z","iopub.execute_input":"2025-01-16T15:23:48.402981Z","iopub.status.idle":"2025-01-16T15:23:48.655618Z","shell.execute_reply.started":"2025-01-16T15:23:48.402948Z","shell.execute_reply":"2025-01-16T15:23:48.654566Z"}},"outputs":[{"name":"stdout","text":"1024\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}